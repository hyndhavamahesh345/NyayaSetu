# NyayaSetu

NyayaSetu is an open-source, offline-first legal assistant. It helps users navigate the transition from old Indian laws (IPC/CrPC/IEA) to the new BNS/BNSS/BSA frameworks. Using local Machine Learning and OCR, it analyzes legal documents and maps law sections with 100% grounded accuracy.

---

## âš–ï¸ NyayaSetu: Law Mapper & Document Analyzer

NyayaSetu is an open-source, offline-first legal assistant. It helps users navigate the transition from old Indian laws (IPC/CrPC/IEA) to the new BNS/BNSS/BSA frameworks. Using local Machine Learning and OCR, it analyzes legal documents and maps law sections with 100% grounded accuracy.

---

### ğŸš€ Key Modules

## ğŸš€ Core Features

- ğŸ”„ **Intelligent Law Mapper:** Maps old IPC sections to new BNS equivalents. Uses an LLM to highlight specific changes in wording, penalties, and scope.
- ğŸ–¼ï¸ **Multimodal OCR Analysis:** Upload photos of legal notices or FIRs. The system extracts text using local OCR and generates actionable summaries.
- ğŸ“š **Grounded Fact-Checking (RAG):** Ask legal questions and get answers backed by official citations. The AI identifies the exact Section and Page from uploaded Law PDFs to prevent hallucinations.
- ğŸ™ï¸ **Environment-Aware Voice Agent:** Features high-fidelity offline TTS (Piper) with an automatic, lightweight cloud fallback (gTTS) to ensure seamless audio playback on headless platforms like Streamlit Cloud.

---

## ğŸ› ï¸ Offline Tech Stack (No-API Approach)

To ensure privacy and offline accessibility, this project can be configured to run without external APIs:

- **Frontend:** Streamlit
- **Backend:** Python, LangChain/LlamaIndex.
- **Local LLM Engine:** Ollama (Llama 3 / Mistral)
- **Voice / TTS:** Piper TTS (ONNX models)
- **OCR Engine:** EasyOCR / PyTesseract
- **Vector Database (RAG):** FAISS + Sentence-Transformers

---

## ğŸ“‚ Project Structure

```css
NyayaSetu/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ nyayasetu-ci.yml  # GitHub Actions CI/CD pipeline
â”œâ”€â”€ engine/
â”‚   â”œâ”€â”€ comparator.py             # AI logic for comparing IPC & BNS texts
â”‚   â”œâ”€â”€ llm.py                    # Fallback logic and LLM summarization
â”‚   â”œâ”€â”€ mapping_logic.py          # Core IPC to BNS transition logic
â”‚   â”œâ”€â”€ ocr_processor.py          # Local OCR extraction and processing
â”‚   â”œâ”€â”€ rag_engine.py             # Local Vector Search logic (FAISS)
â”‚   â””â”€â”€ db.py                     # Database connection and queries
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ timeout_handler.py        # Resiliency and API timeout handlers
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_embeddings.py        # Pytest suite for automated testing
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ ocr_benchmark.py          # OCR character error rate testing
â”œâ”€â”€ models/
â”‚   â””â”€â”€ tts/                      # Local storage for Piper ONNX voice models
â”œâ”€â”€ law_pdfs/                     # Upload directory for Grounded Fact-Checking
â”œâ”€â”€ app.py                        # Main Streamlit UI application
â”œâ”€â”€ Dockerfile                    # Production container configuration
â”œâ”€â”€ requirements.txt              # Python dependencies & OS-specific markers
â”œâ”€â”€ setup_agent.py                # Manual setup script for downloading TTS binaries
â””â”€â”€ README.md                     # Master project documentation
```

---

## âš™ï¸ Installation & Local Setup

### Option A: Using Docker (Recommended)

The easiest way to run NyayaSetu is with Docker. This handles all dependencies (including Tesseract OCR and system libraries) automatically.

1. **Clone the repository:**

   ```bash
   git clone [https://github.com/[username]/NyayaSetu.git](https://github.com/[username]/NyayaSetu.git)
   cd NyayaSetu
   ```

2. **Build the Docker Image in terminal**

   ```bash
   docker build -t nyayasetu .
   ```

3. **Run the Application**

   ```bash
   docker run -p 8501:8501 -e LTA_OLLAMA_URL="[http://host.docker.internal:11434](http://host.docker.internal:11434)" nyayasetu
   ```

4. **Open the App**

   ```bash
   http://localhost:8501
   ```

---

### Option B: Manual Local Setup (Windows/Linux/Mac)

If you prefer to run the app directly in your local Python environment:

1. **Install Dependencies (_requires Python 3.10_)**

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use: venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Download Voice Agent Models**

   ```bash
   python setup_agent.py
   ```

3. **Start the Local LLM**

   ```bash
   ollama serve
   ollama pull llama3
   ```

4. **Launch the App**

   ```bash
   export LTA_OLLAMA_URL="http://localhost:11434"  # On Windows use: set LTA_OLLAMA_URL=http://localhost:11434
   streamlit run app.py
   ```

---

## ğŸŸ¢ Current Implementation Status & Architecture

All core modules, offline LLM integrations, and containerization features are **fully implemented and production-ready**.

```text
   =========================================================================
                  ğŸš€ NYAYASETU: SYSTEM ARCHITECTURE
   =========================================================================

                  [ ğŸ–¥ï¸ Streamlit Frontend (app.py) ]
                                 |
         -------------------------------------------------
         |                       |                       |
   [ ğŸ”„ IPC â†’ BNS Mapper ]  [ ğŸ–¼ï¸ Document OCR ]   [ ğŸ“š Fact-Checker (RAG) ]
         |                       |                       |
   (SQLite Mapping DB)    (EasyOCR / PyTesseract)  (FAISS + sentence-transformers)
         |                       |                       |
         -------------------------------------------------
                                 |
                                 v
                  [ ğŸ§  Local LLM Engine (Ollama) ]
            (Semantic Analysis, Action Items, Summarization)
                                 |
                                 v
                  [ ğŸ™ï¸ Offline Voice Agent (Piper TTS) ]
            (High-fidelity vocal dictation of AI outputs)

   =========================================================================
                     âš™ï¸ INFRASTRUCTURE GUARANTEES
   =========================================================================
   âœ”ï¸ 100% Offline Capable (No external API keys required)
   âœ”ï¸ Dockerized Deployment (Verified networking & TTS dependencies)
   âœ”ï¸ CI/CD Pipeline Active (GitHub Actions + Pytest)
```

---

## ğŸ’¾ Data Persistence & Testing

1. **Local Data Storage (Privacy-First)**
   To maintain our strict offline-first architecture, no user data or legal documents ever leave your machine:

- **Relational Data:** Mappings and system configurations are persisted securely using a local SQLite database (replacing the legacy `mapping_db.json`).
- **Vector Store:** Uploaded law PDFs for Grounded Fact-Checking are processed and stored locally in a FAISS vector index (`./vector_store`).

2. **Automated Testing & CI/CD**
   NyayaSetu maintains high reliability through local testing and GitHub Actions.

   **Local Unit Tests**
   To run the test suite locally, ensure your virtual environment is active (Python 3.10) and execute:

   ```bash
   pip install -r requirements.txt
   pytest -q
   ```

---

## Continuous Integration (GitHub Actions)

Every Pull Request automatically triggers our `.github/workflows/nyayasetu-ci.yml` pipeline.

---

## OCR Benchmark Harness

To evaluate the local OCR engine's Character Error Rate (CER) and Keyword Recall against custom scanned datasets

```bash
python scripts/ocr_benchmark.py --dataset data/ocr_dataset.csv --report ocr_report.md
```

---

## âš™ï¸ Advanced Configuration (Environment Variables)

NyayaSetu is designed to be plug-and-play, but power users can customize the engine behavior using environment variables. If you are using Docker, these are passed via the `-e` flag.

| Variable             | Default                  | Description                                                                                                                            |
| :------------------- | :----------------------- | :------------------------------------------------------------------------------------------------------------------------------------- |
| `LTA_OLLAMA_URL`     | `http://localhost:11434` | The endpoint for the local LLM. When running in Docker, use `http://host.docker.internal:11434` to route traffic to your host machine. |
| `LTA_OLLAMA_MODEL`   | `llama3`                 | Specifies which local model to use for analysis and summarization.                                                                     |
| `LTA_USE_EMBEDDINGS` | `1`                      | Toggles the FAISS/Sentence-Transformer RAG engine. Set to `0` to fallback to legacy keyword search.                                    |

---

## ğŸ—ºï¸ Project Roadmap & Future Scope

All foundational features (Local LLM, OCR, Vector DB, and CI/CD) are fully operational. The next phase of development focuses on expanding accessibility and enterprise utility:

- [ ] **Speech-to-Text (STT) Integration:** Implement local Whisper models to allow users to verbally query the Fact-Checker without typing.
- [ ] **Multilingual Support (Indic Languages):** Translate BNS mappings and OCR summaries into Hindi, Bengali, and other regional languages for broader accessibility.
- [ ] **Precedent & Case Law Expansion:** Expand the RAG Vector Database beyond standard Bare Acts to include landmark judicial precedents.
- [ ] **Automated Legal Briefs:** Add a reporting engine to export OCR analysis and IPC-to-BNS comparisons into cleanly formatted PDF/Docx files.

---

